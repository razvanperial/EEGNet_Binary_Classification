{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from EEGModels import EEGNet\n",
    "import scipy\n",
    "import numpy as np\n",
    "from tensorflow.keras import utils as np_utils\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "from sklearn.metrics import balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./execution_data_clean/P_1.mat', './execution_data_clean/P_10.mat', './execution_data_clean/P_2.mat', './execution_data_clean/P_3.mat', './execution_data_clean/P_4.mat', './execution_data_clean/P_5.mat', './execution_data_clean/P_9.mat', './execution_data_clean/S_1.mat', './execution_data_clean/S_10.mat', './execution_data_clean/S_2.mat', './execution_data_clean/S_3.mat', './execution_data_clean/S_4.mat', './execution_data_clean/S_5.mat', './execution_data_clean/S_9.mat']\n",
      "(75, 14, 1000)\n",
      "(48, 14, 1000)\n",
      "(62, 14, 1000)\n",
      "(77, 14, 1000)\n",
      "(79, 14, 1000)\n",
      "(85, 14, 1000)\n",
      "(73, 14, 1000)\n",
      "(58, 14, 1000)\n",
      "(80, 14, 1000)\n",
      "(64, 14, 1000)\n",
      "(90, 14, 1000)\n",
      "(89, 14, 1000)\n",
      "(72, 14, 1000)\n",
      "(98, 14, 1000)\n"
     ]
    }
   ],
   "source": [
    "folder_path = './execution_data_clean/'\n",
    "file_list = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if file.endswith('.mat')]\n",
    "\n",
    "file_list.sort()\n",
    "\n",
    "print(file_list)\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for i, file in enumerate(file_list):\n",
    "    x = scipy.io.loadmat(file)\n",
    "    x = x['data']\n",
    "\n",
    "    print(x.shape)\n",
    "    \n",
    "    first_letter = file.split('/')[-1][0]\n",
    "\n",
    "    # create output vector. If file begins with 'P', then y = [1,0], else y = [0,1], having the same dimension as x\n",
    "    if first_letter == 'P':\n",
    "        y = np.zeros((x.shape[0],2))\n",
    "        y[:,0] = 1\n",
    "    else:\n",
    "        y = np.zeros((x.shape[0],2))\n",
    "        y[:,1] = 1\n",
    "\n",
    "    X.append(x)\n",
    "    Y.append(y)\n",
    "\n",
    "f = open('data_sizes.txt', 'a')\n",
    "\n",
    "f.write('walk_exec_clean: ' + str(sum([x.shape[0] for x in X])) + '\\n')\n",
    "\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 - 11s - loss: 0.3394 - accuracy: 0.9389 - 11s/epoch - 369ms/step\n",
      "3/3 [==============================] - 0s 34ms/step\n",
      "2/2 [==============================] - 0s 40ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2184: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 42ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2184: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 - 10s - loss: 0.3403 - accuracy: 0.9408 - 10s/epoch - 361ms/step\n",
      "3/3 [==============================] - 0s 36ms/step\n",
      "3/3 [==============================] - 0s 41ms/step\n",
      "5/5 [==============================] - 0s 48ms/step\n",
      "30/30 - 10s - loss: 0.3124 - accuracy: 0.9640 - 10s/epoch - 350ms/step\n",
      "2/2 [==============================] - 0s 28ms/step\n",
      "2/2 [==============================] - 0s 42ms/step\n",
      "4/4 [==============================] - 0s 40ms/step\n",
      "29/29 - 10s - loss: 0.3376 - accuracy: 0.9490 - 10s/epoch - 359ms/step\n",
      "2/2 [==============================] - 0s 24ms/step\n",
      "3/3 [==============================] - 0s 36ms/step\n",
      "4/4 [==============================] - 0s 47ms/step\n",
      "Mean classification accuracy: 0.979323 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "kernels, chans, samples = 1, 14, 1000\n",
    "\n",
    "Accuracies = []\n",
    "p_acc = []\n",
    "s_acc = []\n",
    "\n",
    "for index_1 in range(0, 7):\n",
    "    for index_2 in range(7,14):\n",
    "        # build training set from allfiles expect the ones with index_1 and index_2\n",
    "        X_train = [X[i] for i in range(len(X)) if i != index_1 and i != index_2]\n",
    "        Y_train = [Y[i] for i in range(len(Y)) if i != index_1 and i != index_2]\n",
    "\n",
    "        # build test set from the files with index_1 and index_2\n",
    "        X_test = [X[i] for i in range(len(X)) if i == index_1 or i == index_2]\n",
    "        Y_test = [Y[i] for i in range(len(Y)) if i == index_1 or i == index_2]\n",
    "\n",
    "        X_train = np.concatenate(X_train)\n",
    "        Y_train = np.concatenate(Y_train)\n",
    "\n",
    "        # convert data to NHWC (trials, channels, samples, kernels) format.\n",
    "        X_train = X_train.reshape(X_train.shape[0], chans, samples, kernels)\n",
    "\n",
    "        model = EEGNet(nb_classes=2, Chans=chans, Samples=samples, dropoutRate=0.5, kernLength=32, F1=8, D=2, F2=16, dropoutType='Dropout')\n",
    "\n",
    "        # compile the model and set the optimizers\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "\n",
    "        # count number of parameters in the model\n",
    "        numParams    = model.count_params()     \n",
    "\n",
    "        # set a valid path for the system to record model checkpoints\n",
    "        # checkpointer = ModelCheckpoint(filepath='/tmp/checkpoint.h5', verbose=1, save_best_only=True)\n",
    "\n",
    "        class_weights = {0:1, 1:1}\n",
    "\n",
    "        fitted_model = model.fit(X_train, Y_train, batch_size = 32, epochs = 50, verbose = 2, \n",
    "                                class_weight=class_weights)\n",
    "        \n",
    "        #open file to write results in\n",
    "        f = open(\"results_walk_exec_clean.txt\", \"a\") \n",
    "\n",
    "        # make prediction on the 2 test files individually\n",
    "        X_test_1 = X_test[0].reshape(X_test[0].shape[0], chans, samples, kernels)\n",
    "        X_test_2 = X_test[1].reshape(X_test[1].shape[0], chans, samples, kernels)\n",
    "\n",
    "        probs_1 = model.predict(X_test_1)\n",
    "        probs_2 = model.predict(X_test_2)\n",
    "        preds_1 = probs_1.argmax(axis = -1)\n",
    "        preds_2 = probs_2.argmax(axis = -1)\n",
    "        acc_1 = balanced_accuracy_score(Y_test[0].argmax(axis=-1), preds_1)\n",
    "        acc_2 = balanced_accuracy_score(Y_test[1].argmax(axis=-1), preds_2)\n",
    "        f.write(\"----------------------SELECTED FILES: %d and %d---------------------\\n\" % (index_1, index_2))\n",
    "        f.write(\"Classification accuracy for P: %f \\n\" % (acc_1))\n",
    "        f.write(\"Classification accuracy for S: %f \\n\" % (acc_2))\n",
    "\n",
    "        p_acc.append(acc_1)\n",
    "        s_acc.append(acc_2)\n",
    "\n",
    "        # make prediction on the 2 test files together\n",
    "        X_test = np.concatenate(X_test)\n",
    "        X_test = X_test.reshape(X_test.shape[0], chans, samples, kernels)\n",
    "        Y_test = np.concatenate(Y_test)\n",
    "\n",
    "\n",
    "        probs       = model.predict(X_test)\n",
    "        preds       = probs.argmax(axis = -1)\n",
    "        acc         = balanced_accuracy_score(Y_test.argmax(axis=-1), preds)\n",
    "        f.write(\"Classification accuracy for P and S: %f \\n\" % (acc))\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "        f.close()\n",
    "\n",
    "        Accuracies.append(acc)\n",
    "\n",
    "print(\"Mean classification accuracy: %f \" % (np.mean(Accuracies)))\n",
    "\n",
    "# calculate the mean and std of the accuracies\n",
    "p_acc = np.array(p_acc)\n",
    "s_acc = np.array(s_acc)\n",
    "acc = np.array(Accuracies)\n",
    "\n",
    "f = open(\"results_walk_exec_clean.txt\", \"a\")\n",
    "f.write(\"Mean overall accuracy: %f \\n\" % (np.mean(acc)))\n",
    "f.write(\"Std overall accuracy: %f \\n\" % (np.std(acc)))\n",
    "f.write(\"Mean P accuracy: %f \\n\" % (np.mean(p_acc)))\n",
    "f.write(\"Std P accuracy: %f \\n\" % (np.std(p_acc)))\n",
    "f.write(\"Mean S accuracy: %f \\n\" % (np.mean(s_acc)))\n",
    "f.write(\"Std S accuracy: %f \\n\" % (np.std(s_acc)))\n",
    "f.close()\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coimbra_pythonenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
