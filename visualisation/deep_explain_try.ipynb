{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepexplain.tf.v2_x import DeepExplain\n",
    "from EEGModels import EEGNet\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.backend as K\n",
    "import os\n",
    "import scipy\n",
    "import numpy as np\n",
    "from sklearn.metrics import balanced_accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 14, 500)\n",
      "(37, 14, 500)\n",
      "(49, 14, 500)\n",
      "(56, 14, 500)\n",
      "(58, 14, 500)\n",
      "(57, 14, 500)\n",
      "(60, 14, 500)\n",
      "(60, 14, 500)\n",
      "(67, 14, 500)\n",
      "(60, 14, 500)\n",
      "(80, 14, 500)\n",
      "(79, 14, 500)\n",
      "(66, 14, 500)\n",
      "(84, 14, 500)\n"
     ]
    }
   ],
   "source": [
    "folder_path = '../capped_data/data/walk_instruction_raw/'\n",
    "file_list = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if file.endswith('.mat')]\n",
    "file_list.sort()\n",
    "\n",
    "file_dict = {index: file for index, file in enumerate(file_list)}\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for i, file in enumerate(file_list):\n",
    "    x = scipy.io.loadmat(file)\n",
    "    x = x['data']\n",
    "\n",
    "    x = x[:,:,:500]\n",
    "\n",
    "    print(x.shape)\n",
    "    \n",
    "    first_letter = file.split('/')[-1][0]\n",
    "\n",
    "    # create output vector. If file begins with 'P', then y = [1,0], else y = [0,1], having the same dimension as x\n",
    "    if first_letter == 'P':\n",
    "        y = np.zeros((x.shape[0],2))\n",
    "        y[:,0] = 1\n",
    "    else:\n",
    "        y = np.zeros((x.shape[0],2))\n",
    "        y[:,1] = 1\n",
    "\n",
    "    X.append(x)\n",
    "    Y.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels, chans, samples = 1, 14, 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_1 = 2\n",
    "index_2 = 8\n",
    "\n",
    "X_train = [X[i] for i in range(len(X)) if i != index_1 and i != index_2]\n",
    "Y_train = [Y[i] for i in range(len(Y)) if i != index_1 and i != index_2]\n",
    "\n",
    "# build test set from the files with index_1 and index_2\n",
    "X_test = [X[i] for i in range(len(X)) if i == index_1 or i == index_2]\n",
    "Y_test = [Y[i] for i in range(len(Y)) if i == index_1 or i == index_2]\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "Y_train = np.concatenate(Y_train)\n",
    "X_test = np.concatenate(X_test)\n",
    "Y_test = np.concatenate(Y_test)\n",
    "\n",
    "# convert data to NHWC (trials, channels, samples, kernels) format.\n",
    "X_train = X_train.reshape(X_train.shape[0], chans, samples, kernels)\n",
    "X_test = X_test.reshape(X_test.shape[0], chans, samples, kernels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 753 samples\n",
      "Epoch 1/15\n",
      "753/753 - 5s - loss: 0.6818 - acc: 0.5697 - 5s/epoch - 6ms/sample\n",
      "Epoch 2/15\n",
      "753/753 - 4s - loss: 0.6477 - acc: 0.6308 - 4s/epoch - 5ms/sample\n",
      "Epoch 3/15\n",
      "753/753 - 4s - loss: 0.6377 - acc: 0.6401 - 4s/epoch - 6ms/sample\n",
      "Epoch 4/15\n",
      "753/753 - 4s - loss: 0.6288 - acc: 0.6547 - 4s/epoch - 5ms/sample\n",
      "Epoch 5/15\n",
      "753/753 - 4s - loss: 0.6006 - acc: 0.6972 - 4s/epoch - 5ms/sample\n",
      "Epoch 6/15\n",
      "753/753 - 4s - loss: 0.6048 - acc: 0.6999 - 4s/epoch - 5ms/sample\n",
      "Epoch 7/15\n",
      "753/753 - 4s - loss: 0.5977 - acc: 0.6999 - 4s/epoch - 5ms/sample\n",
      "Epoch 8/15\n",
      "753/753 - 3s - loss: 0.5982 - acc: 0.6932 - 3s/epoch - 5ms/sample\n",
      "Epoch 9/15\n",
      "753/753 - 4s - loss: 0.5806 - acc: 0.7092 - 4s/epoch - 5ms/sample\n",
      "Epoch 10/15\n",
      "753/753 - 4s - loss: 0.5911 - acc: 0.6919 - 4s/epoch - 5ms/sample\n",
      "Epoch 11/15\n",
      "753/753 - 4s - loss: 0.5816 - acc: 0.6985 - 4s/epoch - 5ms/sample\n",
      "Epoch 12/15\n",
      "753/753 - 3s - loss: 0.5719 - acc: 0.6999 - 3s/epoch - 5ms/sample\n",
      "Epoch 13/15\n",
      "753/753 - 3s - loss: 0.5709 - acc: 0.7131 - 3s/epoch - 5ms/sample\n",
      "Epoch 14/15\n",
      "753/753 - 3s - loss: 0.5822 - acc: 0.7185 - 3s/epoch - 5ms/sample\n",
      "Epoch 15/15\n",
      "753/753 - 4s - loss: 0.5580 - acc: 0.7238 - 4s/epoch - 5ms/sample\n"
     ]
    }
   ],
   "source": [
    "model = EEGNet(nb_classes=2, Chans=chans, Samples=samples, dropoutRate=0.5, kernLength=32, F1=8, D=2, F2=16, dropoutType='Dropout')\n",
    "\n",
    "# compile the model and set the optimizers\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "\n",
    "# count number of parameters in the model\n",
    "numParams    = model.count_params()     \n",
    "\n",
    "class_weights = {0:1, 1:1}\n",
    "\n",
    "fitted_model = model.fit(X_train, Y_train, batch_size = 32, epochs = 15, verbose = 2, \n",
    "                        class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_63\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_11 (InputLayer)       [(None, 14, 500, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 14, 500, 8)        256       \n",
      "                                                                 \n",
      " batch_normalization_30 (Bat  (None, 14, 500, 8)       32        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " depthwise_conv2d_10 (Depthw  (None, 1, 500, 16)       224       \n",
      " iseConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_31 (Bat  (None, 1, 500, 16)       64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_20 (Activation)  (None, 1, 500, 16)        0         \n",
      "                                                                 \n",
      " average_pooling2d_20 (Avera  (None, 1, 125, 16)       0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 1, 125, 16)        0         \n",
      "                                                                 \n",
      " separable_conv2d_10 (Separa  (None, 1, 125, 16)       512       \n",
      " bleConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_32 (Bat  (None, 1, 125, 16)       64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_21 (Activation)  (None, 1, 125, 16)        0         \n",
      "                                                                 \n",
      " average_pooling2d_21 (Avera  (None, 1, 15, 16)        0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 1, 15, 16)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 240)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 482       \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,634\n",
      "Trainable params: 1,554\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32 (116, 14, 500, 1)\n",
      "float64 (116, 2)\n",
      "<dtype: 'float32'> (?, 14, 500, 1)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'input_9' defined at (most recent call last):\n    File \"<frozen runpy>\", line 198, in _run_module_as_main\n    File \"<frozen runpy>\", line 88, in _run_code\n    File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\HTPDIR-Laptop1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n      self._run_once()\n    File \"C:\\Users\\HTPDIR-Laptop1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n      handle._run()\n    File \"C:\\Users\\HTPDIR-Laptop1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\HTPDIR-Laptop1\\AppData\\Local\\Temp\\ipykernel_13084\\1698698210.py\", line 1, in <module>\n      model = EEGNet(nb_classes=2, Chans=chans, Samples=samples, dropoutRate=0.5, kernLength=32, F1=8, D=2, F2=16, dropoutType='Dropout')\n    File \"C:\\Users\\HTPDIR-Laptop1\\eeg_net\\arl-eegmodels-master\\EEGModels.py\", line 127, in EEGNet\n      input1   = Input(shape = (Chans, Samples, 1))\n    File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\keras\\engine\\input_layer.py\", line 445, in Input\n      input_layer = InputLayer(**input_layer_config)\n    File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\keras\\engine\\input_layer.py\", line 230, in __init__\n      input_tensor = backend.placeholder(\n    File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\keras\\backend.py\", line 1444, in placeholder\n      x = tf.compat.v1.placeholder(dtype, shape=shape, name=name)\nNode: 'input_9'\nYou must feed a value for placeholder tensor 'input_9' with dtype float and shape [?,14,500,1]\n\t [[{{node input_9}}]]\n\nOriginal stack trace for 'input_9':\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n  File \"<frozen runpy>\", line 88, in _run_code\n  File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n    app.launch_new_instance()\n  File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n    app.start()\n  File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 725, in start\n    self.io_loop.start()\n  File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\HTPDIR-Laptop1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n    self._run_once()\n  File \"C:\\Users\\HTPDIR-Laptop1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n    handle._run()\n  File \"C:\\Users\\HTPDIR-Laptop1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\events.py\", line 80, in _run\n    self._context.run(self._callback, *self._args)\n  File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n    await self.process_one()\n  File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n    await dispatch(*args)\n  File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n    await result\n  File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n    reply_content = await reply_content\n  File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n    res = shell.run_cell(\n  File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n    result = self._run_cell(\n  File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n    result = runner(coro)\n  File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n    coro.send(None)\n  File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n    if await self.run_code(code, result, async_=asy):\n  File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"C:\\Users\\HTPDIR-Laptop1\\AppData\\Local\\Temp\\ipykernel_13084\\1698698210.py\", line 1, in <module>\n    model = EEGNet(nb_classes=2, Chans=chans, Samples=samples, dropoutRate=0.5, kernLength=32, F1=8, D=2, F2=16, dropoutType='Dropout')\n  File \"C:\\Users\\HTPDIR-Laptop1\\eeg_net\\arl-eegmodels-master\\EEGModels.py\", line 127, in EEGNet\n    input1   = Input(shape = (Chans, Samples, 1))\n  File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n    return fn(*args, **kwargs)\n  File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\keras\\engine\\input_layer.py\", line 445, in Input\n    input_layer = InputLayer(**input_layer_config)\n  File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n    return fn(*args, **kwargs)\n  File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\keras\\engine\\input_layer.py\", line 230, in __init__\n    input_tensor = backend.placeholder(\n  File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\keras\\backend.py\", line 1444, in placeholder\n    x = tf.compat.v1.placeholder(dtype, shape=shape, name=name)\n  File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 3361, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 8693, in placeholder\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 795, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3814, in _create_op_internal\n    ret = Operation(\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\tensorflow\\python\\client\\session.py:1378\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1378\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m   1379\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mOpError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\tensorflow\\python\\client\\session.py:1361\u001b[0m, in \u001b[0;36mBaseSession._do_run.<locals>._run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1360\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_extend_graph()\n\u001b[1;32m-> 1361\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m   1362\u001b[0m                                 target_list, run_metadata)\n",
      "File \u001b[1;32mc:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\tensorflow\\python\\client\\session.py:1454\u001b[0m, in \u001b[0;36mBaseSession._call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1452\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_tf_sessionrun\u001b[39m(\u001b[39mself\u001b[39m, options, feed_dict, fetch_list, target_list,\n\u001b[0;32m   1453\u001b[0m                         run_metadata):\n\u001b[1;32m-> 1454\u001b[0m   \u001b[39mreturn\u001b[39;00m tf_session\u001b[39m.\u001b[39;49mTF_SessionRun_wrapper(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_session, options, feed_dict,\n\u001b[0;32m   1455\u001b[0m                                           fetch_list, target_list,\n\u001b[0;32m   1456\u001b[0m                                           run_metadata)\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'input_9' with dtype float and shape [?,14,500,1]\n\t [[{{node input_9}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[175], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m target_tensor  \u001b[39m=\u001b[39m fModel(input_tensor)    \n\u001b[0;32m     13\u001b[0m \u001b[39m# can use epsilon-LRP as well if you like.\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m attributions   \u001b[39m=\u001b[39m de\u001b[39m.\u001b[39;49mexplain(\u001b[39m'\u001b[39;49m\u001b[39mdeeplift\u001b[39;49m\u001b[39m'\u001b[39;49m, target_tensor, input_tensor, X_test, ys\u001b[39m=\u001b[39;49mY_test)\n\u001b[0;32m     15\u001b[0m \u001b[39m# attributions = de.explain('elrp', target_tensor * Y_test, input_tensor, X_test)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\deepexplain\\tf\\v2_x\\main.py:106\u001b[0m, in \u001b[0;36mDeepExplain.explain\u001b[1;34m(self, method, T, X, xs, ys, batch_size, **kwargs)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mexplain\u001b[39m(\u001b[39mself\u001b[39m, method, T, X, xs, ys\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, batch_size\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 106\u001b[0m     explainer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_explainer(method, T, X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    107\u001b[0m     \u001b[39mreturn\u001b[39;00m explainer\u001b[39m.\u001b[39mrun(xs, ys, batch_size)\n",
      "File \u001b[1;32mc:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\deepexplain\\tf\\v2_x\\main.py:90\u001b[0m, in \u001b[0;36mDeepExplain.get_explainer\u001b[1;34m(self, method, T, X, **kwargs)\u001b[0m\n\u001b[0;32m     87\u001b[0m constants\u001b[39m.\u001b[39m_GRAD_OVERRIDE_CHECKFLAG \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     89\u001b[0m constants\u001b[39m.\u001b[39m_ENABLED_METHOD_CLASS \u001b[39m=\u001b[39m method_class\n\u001b[1;32m---> 90\u001b[0m method \u001b[39m=\u001b[39m constants\u001b[39m.\u001b[39;49m_ENABLED_METHOD_CLASS(T, X,\n\u001b[0;32m     91\u001b[0m                                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msession,\n\u001b[0;32m     92\u001b[0m                                 keras_learning_phase\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkeras_phase_placeholder,\n\u001b[0;32m     93\u001b[0m                                \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     95\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39missubclass\u001b[39m(constants\u001b[39m.\u001b[39m_ENABLED_METHOD_CLASS, DeepLIFTRescale) \u001b[39mor\u001b[39;00m \u001b[39missubclass\u001b[39m(constants\u001b[39m.\u001b[39m_ENABLED_METHOD_CLASS, EpsilonLRP)) \\\n\u001b[0;32m     96\u001b[0m \u001b[39mand\u001b[39;00m constants\u001b[39m.\u001b[39m_GRAD_OVERRIDE_CHECKFLAG \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     97\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39m'\u001b[39m\u001b[39mDeepExplain detected you are trying to use an attribution method that requires \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     98\u001b[0m                     \u001b[39m'\u001b[39m\u001b[39mgradient override but the original gradient was used instead. You might have forgot to \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     99\u001b[0m                     \u001b[39m'\u001b[39m\u001b[39m(re)create your graph within the DeepExlain context. Results are not reliable!\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\deepexplain\\tf\\v2_x\\methods.py:130\u001b[0m, in \u001b[0;36mDeepLIFTRescale.__init__\u001b[1;34m(self, T, X, session, keras_learning_phase, baseline, Y_shape)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, T, X, session, keras_learning_phase, baseline\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, Y_shape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    129\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbaseline \u001b[39m=\u001b[39m baseline\n\u001b[1;32m--> 130\u001b[0m     \u001b[39msuper\u001b[39;49m(DeepLIFTRescale, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(T, X, session, keras_learning_phase, Y_shape)\n",
      "File \u001b[1;32mc:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\deepexplain\\tf\\v2_x\\baseClasses.py:39\u001b[0m, in \u001b[0;36mAttributionMethod.__init__\u001b[1;34m(self, T, X, session, keras_learning_phase, Y_shape)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_check_baseline()\n\u001b[0;32m     38\u001b[0m \u001b[39m# References\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init_references()\n\u001b[0;32m     41\u001b[0m \u001b[39m# Create symbolic explanation once during construction (affects only gradient-based methods)\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexplain_symbolic()\n",
      "File \u001b[1;32mc:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\deepexplain\\tf\\v2_x\\methods.py:160\u001b[0m, in \u001b[0;36mDeepLIFTRescale._init_references\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[39mif\u001b[39;00m op\u001b[39m.\u001b[39mtype \u001b[39min\u001b[39;00m constants\u001b[39m.\u001b[39mSUPPORTED_ACTIVATIONS:\n\u001b[0;32m    159\u001b[0m             ops\u001b[39m.\u001b[39mappend(op)\n\u001b[1;32m--> 160\u001b[0m YR \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_session_run([o\u001b[39m.\u001b[39;49minputs[\u001b[39m0\u001b[39;49m] \u001b[39mfor\u001b[39;49;00m o \u001b[39min\u001b[39;49;00m ops], \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbaseline)\n\u001b[0;32m    161\u001b[0m \u001b[39mfor\u001b[39;00m (r, op) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(YR, ops):\n\u001b[0;32m    162\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_deeplift_ref[op\u001b[39m.\u001b[39mname] \u001b[39m=\u001b[39m r\n",
      "File \u001b[1;32mc:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\deepexplain\\tf\\v2_x\\baseClasses.py:100\u001b[0m, in \u001b[0;36mAttributionMethod._session_run\u001b[1;34m(self, T, xs, ys, batch_size)\u001b[0m\n\u001b[0;32m     96\u001b[0m                 \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mEvaluation in batches requires all inputs to have \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     97\u001b[0m                                     \u001b[39m'\u001b[39m\u001b[39mthe same number of samples\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     99\u001b[0m \u001b[39mif\u001b[39;00m batch_size \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m batch_size \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m num_samples \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m batch_size:\n\u001b[1;32m--> 100\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_session_run_batch(T, xs, ys)\n\u001b[0;32m    101\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    102\u001b[0m     outs \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\deepexplain\\tf\\v2_x\\baseClasses.py:84\u001b[0m, in \u001b[0;36mAttributionMethod._session_run_batch\u001b[1;34m(self, T, xs, ys)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkeras_learning_phase \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     83\u001b[0m     feed_dict[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkeras_learning_phase] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m---> 84\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mrun(T, feed_dict)\n",
      "File \u001b[1;32mc:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\tensorflow\\python\\client\\session.py:968\u001b[0m, in \u001b[0;36mBaseSession.run\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    965\u001b[0m run_metadata_ptr \u001b[39m=\u001b[39m tf_session\u001b[39m.\u001b[39mTF_NewBuffer() \u001b[39mif\u001b[39;00m run_metadata \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    967\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 968\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(\u001b[39mNone\u001b[39;49;00m, fetches, feed_dict, options_ptr,\n\u001b[0;32m    969\u001b[0m                      run_metadata_ptr)\n\u001b[0;32m    970\u001b[0m   \u001b[39mif\u001b[39;00m run_metadata:\n\u001b[0;32m    971\u001b[0m     proto_data \u001b[39m=\u001b[39m tf_session\u001b[39m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "File \u001b[1;32mc:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\tensorflow\\python\\client\\session.py:1191\u001b[0m, in \u001b[0;36mBaseSession._run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1188\u001b[0m \u001b[39m# We only want to really perform the run if fetches or targets are provided,\u001b[39;00m\n\u001b[0;32m   1189\u001b[0m \u001b[39m# or if the call is a partial run that specifies feeds.\u001b[39;00m\n\u001b[0;32m   1190\u001b[0m \u001b[39mif\u001b[39;00m final_fetches \u001b[39mor\u001b[39;00m final_targets \u001b[39mor\u001b[39;00m (handle \u001b[39mand\u001b[39;00m feed_dict_tensor):\n\u001b[1;32m-> 1191\u001b[0m   results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_run(handle, final_targets, final_fetches,\n\u001b[0;32m   1192\u001b[0m                          feed_dict_tensor, options, run_metadata)\n\u001b[0;32m   1193\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1194\u001b[0m   results \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\tensorflow\\python\\client\\session.py:1371\u001b[0m, in \u001b[0;36mBaseSession._do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1368\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_tf_sessionprun(handle, feed_dict, fetch_list)\n\u001b[0;32m   1370\u001b[0m \u001b[39mif\u001b[39;00m handle \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1371\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m   1372\u001b[0m                        run_metadata)\n\u001b[0;32m   1373\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1374\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_do_call(_prun_fn, handle, feeds, fetches)\n",
      "File \u001b[1;32mc:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\tensorflow\\python\\client\\session.py:1397\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1392\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39monly supports NHWC tensor format\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m message:\n\u001b[0;32m   1393\u001b[0m   message \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mA possible workaround: Try disabling Grappler optimizer\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1394\u001b[0m               \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mby modifying the config for creating the session eg.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1395\u001b[0m               \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39msession_config.graph_options.rewrite_options.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1396\u001b[0m               \u001b[39m'\u001b[39m\u001b[39mdisable_meta_optimizer = True\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m-> 1397\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mtype\u001b[39m(e)(node_def, op, message)\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'input_9' defined at (most recent call last):\n    File \"<frozen runpy>\", line 198, in _run_module_as_main\n    File \"<frozen runpy>\", line 88, in _run_code\n    File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\HTPDIR-Laptop1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n      self._run_once()\n    File \"C:\\Users\\HTPDIR-Laptop1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n      handle._run()\n    File \"C:\\Users\\HTPDIR-Laptop1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\HTPDIR-Laptop1\\AppData\\Local\\Temp\\ipykernel_13084\\1698698210.py\", line 1, in <module>\n      model = EEGNet(nb_classes=2, Chans=chans, Samples=samples, dropoutRate=0.5, kernLength=32, F1=8, D=2, F2=16, dropoutType='Dropout')\n    File \"C:\\Users\\HTPDIR-Laptop1\\eeg_net\\arl-eegmodels-master\\EEGModels.py\", line 127, in EEGNet\n      input1   = Input(shape = (Chans, Samples, 1))\n    File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\keras\\engine\\input_layer.py\", line 445, in Input\n      input_layer = InputLayer(**input_layer_config)\n    File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\keras\\engine\\input_layer.py\", line 230, in __init__\n      input_tensor = backend.placeholder(\n    File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\keras\\backend.py\", line 1444, in placeholder\n      x = tf.compat.v1.placeholder(dtype, shape=shape, name=name)\nNode: 'input_9'\nYou must feed a value for placeholder tensor 'input_9' with dtype float and shape [?,14,500,1]\n\t [[{{node input_9}}]]\n\nOriginal stack trace for 'input_9':\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n  File \"<frozen runpy>\", line 88, in _run_code\n  File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n    app.launch_new_instance()\n  File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n    app.start()\n  File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 725, in start\n    self.io_loop.start()\n  File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\HTPDIR-Laptop1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n    self._run_once()\n  File \"C:\\Users\\HTPDIR-Laptop1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n    handle._run()\n  File \"C:\\Users\\HTPDIR-Laptop1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\events.py\", line 80, in _run\n    self._context.run(self._callback, *self._args)\n  File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n    await self.process_one()\n  File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n    await dispatch(*args)\n  File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n    await result\n  File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n    reply_content = await reply_content\n  File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n    res = shell.run_cell(\n  File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n    result = self._run_cell(\n  File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n    result = runner(coro)\n  File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n    coro.send(None)\n  File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n    if await self.run_code(code, result, async_=asy):\n  File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"C:\\Users\\HTPDIR-Laptop1\\AppData\\Local\\Temp\\ipykernel_13084\\1698698210.py\", line 1, in <module>\n    model = EEGNet(nb_classes=2, Chans=chans, Samples=samples, dropoutRate=0.5, kernLength=32, F1=8, D=2, F2=16, dropoutType='Dropout')\n  File \"C:\\Users\\HTPDIR-Laptop1\\eeg_net\\arl-eegmodels-master\\EEGModels.py\", line 127, in EEGNet\n    input1   = Input(shape = (Chans, Samples, 1))\n  File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n    return fn(*args, **kwargs)\n  File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\keras\\engine\\input_layer.py\", line 445, in Input\n    input_layer = InputLayer(**input_layer_config)\n  File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n    return fn(*args, **kwargs)\n  File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\keras\\engine\\input_layer.py\", line 230, in __init__\n    input_tensor = backend.placeholder(\n  File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\keras\\backend.py\", line 1444, in placeholder\n    x = tf.compat.v1.placeholder(dtype, shape=shape, name=name)\n  File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 3361, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 8693, in placeholder\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 795, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"c:\\Users\\HTPDIR-Laptop1\\eeg_net_env\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3814, in _create_op_internal\n    ret = Operation(\n"
     ]
    }
   ],
   "source": [
    "# np.float32(Y_test)\n",
    "# print(X_test.dtype, X_test.shape)\n",
    "# print(Y_test.dtype, Y_test.shape)\n",
    "X = tf.placeholder(\"float\", [None, chans, samples, kernels])\n",
    "Y = tf.placeholder(\"float\", [None, 2])\n",
    "print(X.dtype, X.shape)\n",
    "print(Y.dtype, Y.shape)\n",
    "\n",
    "with DeepExplain(session = tf.compat.v1.keras.backend.get_session()) as de:\n",
    "\tinput_tensor = model.input\n",
    "\tfModel         = Model(inputs = input_tensor, outputs = model.layers[-2].output)    \n",
    "\ttarget_tensor  = fModel(input_tensor)    \n",
    "\n",
    "\t# can use epsilon-LRP as well if you like.\n",
    "\tattributions   = de.explain('deeplift', target_tensor, input_tensor, X_test, ys=Y_test)\n",
    "\t# attributions = de.explain('elrp', target_tensor * Y_test, input_tensor, X_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg_net_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
