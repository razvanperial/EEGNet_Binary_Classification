{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from EEGModels import EEGNet\n",
    "import scipy\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras import utils as np_utils\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.model_selection import LeaveOneOut\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'P_1.mat', 1: 'P_10.mat', 2: 'P_2.mat', 3: 'P_3.mat', 4: 'P_4.mat', 5: 'P_5.mat', 6: 'P_9.mat'}\n",
      "['../condition_data/dance/raw/exec/P_1.mat', '../condition_data/dance/raw/exec/P_10.mat', '../condition_data/dance/raw/exec/P_2.mat', '../condition_data/dance/raw/exec/P_3.mat', '../condition_data/dance/raw/exec/P_4.mat', '../condition_data/dance/raw/exec/P_5.mat', '../condition_data/dance/raw/exec/P_9.mat']\n",
      "['../condition_data/walk/raw/exec/P_1.mat', '../condition_data/walk/raw/exec/P_10.mat', '../condition_data/walk/raw/exec/P_2.mat', '../condition_data/walk/raw/exec/P_3.mat', '../condition_data/walk/raw/exec/P_4.mat', '../condition_data/walk/raw/exec/P_5.mat', '../condition_data/walk/raw/exec/P_9.mat']\n",
      "(79, 14, 1000) (79, 3)\n",
      "(56, 14, 1000) (56, 3)\n",
      "(78, 14, 1000) (78, 3)\n",
      "(80, 14, 1000) (80, 3)\n",
      "(116, 14, 1000) (116, 3)\n",
      "(85, 14, 1000) (85, 3)\n",
      "(89, 14, 1000) (89, 3)\n",
      "(84, 14, 1000) (84, 3)\n",
      "(55, 14, 1000) (55, 3)\n",
      "(74, 14, 1000) (74, 3)\n",
      "(84, 14, 1000) (84, 3)\n",
      "(86, 14, 1000) (86, 3)\n",
      "(87, 14, 1000) (87, 3)\n",
      "(90, 14, 1000) (90, 3)\n"
     ]
    }
   ],
   "source": [
    "folder_path_dance = '../condition_data/dance/raw/exec/'\n",
    "folder_path_walk = '../condition_data/walk/raw/exec/'\n",
    "\n",
    "file_list_dance = [os.path.join(folder_path_dance, file) for file in os.listdir(folder_path_dance) if file.startswith('P')]\n",
    "file_list_walk = [os.path.join(folder_path_walk, file) for file in os.listdir(folder_path_walk) if file.startswith('P')]\n",
    "\n",
    "file_list_dance.sort()\n",
    "file_list_walk.sort()\n",
    "\n",
    "# create a dictionary that maps indices to file names\n",
    "file_dict_dance = {index: file_name.split(\"/\")[-1] for index, file_name in enumerate(file_list_dance)}\n",
    "file_dict_walk = {index: file_name.split(\"/\")[-1] for index, file_name in enumerate(file_list_walk)}\n",
    "\n",
    "X_dance = []\n",
    "Y_dance = []\n",
    "X_walk = []\n",
    "Y_walk = []\n",
    "\n",
    "for file in file_list_dance:\n",
    "    dataset = scipy.io.loadmat(file)\n",
    "    x = dataset['data']\n",
    "    y = dataset['labels']\n",
    "\n",
    "    if(y[0] < 4):\n",
    "        sys.exit(\"Incorrect label found!\")\n",
    "\n",
    "    y -= 3\n",
    "    y = np_utils.to_categorical(y-1)\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "\n",
    "    X_dance.append(x)\n",
    "    Y_dance.append(y)\n",
    "\n",
    "for file in file_list_walk:\n",
    "    dataset = scipy.io.loadmat(file)\n",
    "    x = dataset['data']\n",
    "    y = dataset['labels']\n",
    "\n",
    "    if(y[0] < 4):\n",
    "        sys.exit(\"Incorrect label found!\")\n",
    "\n",
    "    y -= 3\n",
    "    y = np_utils.to_categorical(y-1)\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "    X_walk.append(x)\n",
    "    Y_walk.append(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('../condition_results/data_sizes.txt', 'a')\n",
    "f.write('P_Dance_Exec: ' + str(sum(x.shape[0] for x in X_dance)) + '\\n')\n",
    "f.write('P_Walk_Exec: ' + str(sum(x.shape[0] for x in X_walk)) + '\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels, chans, samples = 1, 14, 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(504, 14, 1000) (504, 3)\n",
      "(527, 14, 1000) (527, 3)\n",
      "(505, 14, 1000) (505, 3)\n",
      "(503, 14, 1000) (503, 3)\n",
      "(467, 14, 1000) (467, 3)\n",
      "(498, 14, 1000) (498, 3)\n",
      "(494, 14, 1000) (494, 3)\n"
     ]
    }
   ],
   "source": [
    "f = open('../condition_results/P_exec.txt', 'a')\n",
    "f.write('-----------------DANCE-----------------\\n')\n",
    "f.close()\n",
    "\n",
    "dance_accuracies = []\n",
    "\n",
    "dance_loo = LeaveOneOut()\n",
    "\n",
    "for train_index, test_index in dance_loo.split(X_dance):\n",
    "    X_train = np.concatenate([X_dance[i] for i in train_index])\n",
    "    Y_train = np.concatenate([Y_dance[i] for i in train_index])\n",
    "\n",
    "    X_test = np.concatenate([X_dance[i] for i in test_index])\n",
    "    Y_test = np.concatenate([Y_dance[i] for i in test_index])\n",
    "    \n",
    "    print(\"ITERATION NUMBER: \" + str(test_index[0]))\n",
    "\n",
    "    # convert data to NHWC (trials, channels, samples, kernels) format.\n",
    "    X_train = X_train.reshape(X_train.shape[0], chans, samples, kernels)\n",
    "    X_test = X_test.reshape(X_test.shape[0], chans, samples, kernels)\n",
    "\n",
    "    # define EEGNet model\n",
    "    model = EEGNet(nb_classes=3, Chans=chans, Samples=samples, dropoutRate=0.5, \n",
    "                   kernLength=32, F1=8, D=2, F2=16, dropoutType='Dropout')\n",
    "\n",
    "    # compile the model and set the optimizers\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "\n",
    "    # count number of parameters in the model\n",
    "    numParams    = model.count_params() \n",
    "\n",
    "    # set initial class weights\n",
    "    class_weights = {0: 1., 1: 1., 2: 1.}\n",
    "    \n",
    "    # fit the model\n",
    "    fitted_model = model.fit(X_train, Y_train, batch_size = 32, epochs = 50, verbose = 2, \n",
    "                             class_weight=class_weights)\n",
    "    \n",
    "    # make prediction on test set.\n",
    "    probs = model.predict(X_test)\n",
    "    preds = probs.argmax(axis = -1)\n",
    "    acc = balanced_accuracy_score(Y_test.argmax(axis = -1), preds)\n",
    "    dance_accuracies.append(acc)\n",
    "\n",
    "    f = open('../condition_results/P_exec.txt', 'a')\n",
    "    f.write(file_dict_dance[test_index[0]] + ': ' + str(acc) + '\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('../condition_results/P_exec.txt', 'a')\n",
    "f.write('-----------------WALK-----------------\\n')\n",
    "f.close()\n",
    "\n",
    "walk_accuracies = []\n",
    "\n",
    "walk_loo = LeaveOneOut()\n",
    "\n",
    "for train_index, test_index in walk_loo.split(X_walk):\n",
    "    X_train = np.concatenate([X_walk[i] for i in train_index])\n",
    "    Y_train = np.concatenate([Y_walk[i] for i in train_index])\n",
    "\n",
    "    X_test = np.concatenate([X_walk[i] for i in test_index])\n",
    "    Y_test = np.concatenate([Y_walk[i] for i in test_index])\n",
    "    \n",
    "    print(\"ITERATION NUMBER: \" + str(test_index[0]))\n",
    "\n",
    "    # convert data to NHWC (trials, channels, samples, kernels) format.\n",
    "    X_train = X_train.reshape(X_train.shape[0], chans, samples, kernels)\n",
    "    X_test = X_test.reshape(X_test.shape[0], chans, samples, kernels)\n",
    "\n",
    "    # define EEGNet model\n",
    "    model = EEGNet(nb_classes=3, Chans=chans, Samples=samples, dropoutRate=0.5, \n",
    "                   kernLength=32, F1=8, D=2, F2=16, dropoutType='Dropout')\n",
    "\n",
    "    # compile the model and set the optimizers\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "\n",
    "    # count number of parameters in the model\n",
    "    numParams    = model.count_params() \n",
    "\n",
    "    # set initial class weights\n",
    "    class_weights = {0: 1., 1: 1., 2: 1.}\n",
    "    \n",
    "    # fit the model\n",
    "    fitted_model = model.fit(X_train, Y_train, batch_size = 32, epochs = 50, verbose = 2, \n",
    "                             class_weight=class_weights)\n",
    "    \n",
    "    # make prediction on test set.\n",
    "    probs = model.predict(X_test)\n",
    "    preds = probs.argmax(axis = -1)\n",
    "    acc = balanced_accuracy_score(Y_test.argmax(axis = -1), preds)\n",
    "    walk_accuracies.append(acc)\n",
    "\n",
    "    f = open('../condition_results/P_exec.txt', 'a')\n",
    "    f.write(file_dict_walk[test_index[0]] + ': ' + str(acc) + '\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('../condition_results/P_exec.txt', 'a')\n",
    "\n",
    "f.write('\\n\\nP_Dance_accuracy: ' + str(np.mean(dance_accuracies)) + '\\n')\n",
    "f.write('P_Dance_std: ' + str(np.std(dance_accuracies)) + '\\n')\n",
    "\n",
    "f.write('P_Walk_accuracy: ' + str(np.mean(walk_accuracies)) + '\\n')\n",
    "f.write('P_Walk_std: ' + str(np.std(walk_accuracies)) + '\\n')\n",
    "\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg_net_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
