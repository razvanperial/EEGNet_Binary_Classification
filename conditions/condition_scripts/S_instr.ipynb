{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from EEGModels import EEGNet\n",
    "import scipy\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras import utils as np_utils\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.model_selection import LeaveOneOut\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(104, 14, 750) (104, 3)\n",
      "(77, 14, 750) (77, 3)\n",
      "(89, 14, 750) (89, 3)\n",
      "(119, 14, 750) (119, 3)\n",
      "(95, 14, 750) (95, 3)\n",
      "(100, 14, 750) (100, 3)\n",
      "(96, 14, 750) (96, 3)\n",
      "(90, 14, 750) (90, 3)\n",
      "(98, 14, 750) (98, 3)\n",
      "(90, 14, 750) (90, 3)\n",
      "(120, 14, 750) (120, 3)\n",
      "(118, 14, 750) (118, 3)\n",
      "(97, 14, 750) (97, 3)\n",
      "(124, 14, 750) (124, 3)\n"
     ]
    }
   ],
   "source": [
    "folder_path_dance = '../condition_data/dance/raw/inst/'\n",
    "folder_path_walk = '../condition_data/walk/raw/inst/'\n",
    "\n",
    "file_list_dance = [os.path.join(folder_path_dance, file) for file in os.listdir(folder_path_dance) if file.startswith('S')]\n",
    "file_list_walk = [os.path.join(folder_path_walk, file) for file in os.listdir(folder_path_walk) if file.startswith('S')]\n",
    "\n",
    "file_list_dance.sort()\n",
    "file_list_walk.sort()\n",
    "\n",
    "# create a dictionary that maps indices to file names\n",
    "file_dict_dance = {index: file_name.split(\"/\")[-1] for index, file_name in enumerate(file_list_dance)}\n",
    "file_dict_walk = {index: file_name.split(\"/\")[-1] for index, file_name in enumerate(file_list_walk)}\n",
    "\n",
    "X_dance = []\n",
    "Y_dance = []\n",
    "X_walk = []\n",
    "Y_walk = []\n",
    "\n",
    "for file in file_list_dance:\n",
    "    dataset = scipy.io.loadmat(file)\n",
    "    x = dataset['data']\n",
    "    y = dataset['labels']\n",
    "\n",
    "    if(y[0] > 3):\n",
    "        sys.exit(\"Incorrect label found!\")\n",
    "\n",
    "    y = np_utils.to_categorical(y-1)\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "\n",
    "    X_dance.append(x)\n",
    "    Y_dance.append(y)\n",
    "\n",
    "for file in file_list_walk:\n",
    "    dataset = scipy.io.loadmat(file)\n",
    "    x = dataset['data']\n",
    "    y = dataset['labels']\n",
    "\n",
    "    if(y[0] > 3):\n",
    "        sys.exit(\"Incorrect label found!\")\n",
    "\n",
    "    y = np_utils.to_categorical(y-1)\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "    X_walk.append(x)\n",
    "    Y_walk.append(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('../condition_results/data_sizes.txt', 'a')\n",
    "f.write('S_Dance_Inst: ' + str(sum(x.shape[0] for x in X_dance)) + '\\n')\n",
    "f.write('S_Walk_Inst: ' + str(sum(x.shape[0] for x in X_walk)) + '\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels, chans, samples = 1, 14, 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION NUMBER: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION NUMBER: 1\n",
      "ITERATION NUMBER: 2\n",
      "ITERATION NUMBER: 3\n",
      "ITERATION NUMBER: 4\n",
      "ITERATION NUMBER: 5\n",
      "ITERATION NUMBER: 6\n"
     ]
    }
   ],
   "source": [
    "f = open('../condition_results/S_inst.txt', 'a')\n",
    "f.write('-----------------DANCE-----------------\\n')\n",
    "f.close()\n",
    "\n",
    "dance_accuracies = []\n",
    "\n",
    "dance_loo = LeaveOneOut()\n",
    "\n",
    "for train_index, test_index in dance_loo.split(X_dance):\n",
    "    X_train = np.concatenate([X_dance[i] for i in train_index])\n",
    "    Y_train = np.concatenate([Y_dance[i] for i in train_index])\n",
    "\n",
    "    X_test = np.concatenate([X_dance[i] for i in test_index])\n",
    "    Y_test = np.concatenate([Y_dance[i] for i in test_index])\n",
    "\n",
    "    print(\"ITERATION NUMBER: \" + str(test_index[0]))\n",
    "    \n",
    "    # convert data to NHWC (trials, channels, samples, kernels) format.\n",
    "    X_train = X_train.reshape(X_train.shape[0], chans, samples, kernels)\n",
    "    X_test = X_test.reshape(X_test.shape[0], chans, samples, kernels)\n",
    "\n",
    "    # define EEGNet model\n",
    "    model = EEGNet(nb_classes=3, Chans=chans, Samples=samples, dropoutRate=0.5, \n",
    "                   kernLength=32, F1=8, D=2, F2=16, dropoutType='Dropout')\n",
    "\n",
    "    # compile the model and set the optimizers\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "\n",
    "    # count number of parameters in the model\n",
    "    numParams    = model.count_params() \n",
    "\n",
    "    # set initial class weights\n",
    "    class_weights = {0: 1., 1: 1., 2: 1.}\n",
    "    \n",
    "    # fit the model\n",
    "    fitted_model = model.fit(X_train, Y_train, batch_size = 32, epochs = 50, verbose = 2, \n",
    "                             class_weight=class_weights)\n",
    "    \n",
    "    # make prediction on test set.\n",
    "    probs = model.predict(X_test)\n",
    "    preds = probs.argmax(axis = -1)\n",
    "    acc = balanced_accuracy_score(Y_test.argmax(axis = -1), preds)\n",
    "    dance_accuracies.append(acc)\n",
    "\n",
    "    f = open('../condition_results/S_inst.txt', 'a')\n",
    "    f.write(file_dict_dance[test_index[0]] + ': ' + str(acc) + '\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION NUMBER: 0\n",
      "ITERATION NUMBER: 1\n",
      "ITERATION NUMBER: 2\n",
      "ITERATION NUMBER: 3\n",
      "ITERATION NUMBER: 4\n",
      "ITERATION NUMBER: 5\n",
      "ITERATION NUMBER: 6\n"
     ]
    }
   ],
   "source": [
    "f = open('../condition_results/S_inst.txt', 'a')\n",
    "f.write('-----------------WALK-----------------\\n')\n",
    "f.close()\n",
    "\n",
    "walk_accuracies = []\n",
    "\n",
    "walk_loo = LeaveOneOut()\n",
    "\n",
    "for train_index, test_index in walk_loo.split(X_walk):\n",
    "    X_train = np.concatenate([X_walk[i] for i in train_index])\n",
    "    Y_train = np.concatenate([Y_walk[i] for i in train_index])\n",
    "\n",
    "    X_test = np.concatenate([X_walk[i] for i in test_index])\n",
    "    Y_test = np.concatenate([Y_walk[i] for i in test_index])\n",
    "\n",
    "    print(\"ITERATION NUMBER: \" + str(test_index[0]))\n",
    "\n",
    "    # convert data to NHWC (trials, channels, samples, kernels) format.\n",
    "    X_train = X_train.reshape(X_train.shape[0], chans, samples, kernels)\n",
    "    X_test = X_test.reshape(X_test.shape[0], chans, samples, kernels)\n",
    "\n",
    "    # define EEGNet model\n",
    "    model = EEGNet(nb_classes=3, Chans=chans, Samples=samples, dropoutRate=0.5, \n",
    "                   kernLength=32, F1=8, D=2, F2=16, dropoutType='Dropout')\n",
    "\n",
    "    # compile the model and set the optimizers\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "\n",
    "    # count number of parameters in the model\n",
    "    numParams    = model.count_params() \n",
    "\n",
    "    # set initial class weights\n",
    "    class_weights = {0: 1., 1: 1., 2: 1.}\n",
    "    \n",
    "    # fit the model\n",
    "    fitted_model = model.fit(X_train, Y_train, batch_size = 32, epochs = 50, verbose = 2, \n",
    "                             class_weight=class_weights)\n",
    "    \n",
    "    # make prediction on test set.\n",
    "    probs = model.predict(X_test)\n",
    "    preds = probs.argmax(axis = -1)\n",
    "    acc = balanced_accuracy_score(Y_test.argmax(axis = -1), preds)\n",
    "    walk_accuracies.append(acc)\n",
    "\n",
    "    f = open('../condition_results/S_inst.txt', 'a')\n",
    "    f.write(file_dict_walk[test_index[0]] + ': ' + str(acc) + '\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('../condition_results/S_inst.txt', 'a')\n",
    "\n",
    "f.write('\\n\\nS_Dance_accuracy: ' + str(np.mean(dance_accuracies)) + '\\n')\n",
    "f.write('S_Dance_std: ' + str(np.std(dance_accuracies)) + '\\n')\n",
    "\n",
    "f.write('S_Walk_accuracy: ' + str(np.mean(walk_accuracies)) + '\\n')\n",
    "f.write('S_Walk_std: ' + str(np.std(walk_accuracies)) + '\\n')\n",
    "\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg_net_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
